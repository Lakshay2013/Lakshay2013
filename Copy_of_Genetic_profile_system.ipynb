{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSviizS3cnmvd/rMmneF4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lakshay2013/Lakshay2013/blob/main/Copy_of_Genetic_profile_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GeneQuest™ Genetic Profiling System\n",
        "Phoenix labs"
      ],
      "metadata": {
        "id": "t7ejoGkVopXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Dataset Preparation**  \n",
        "- **Source**: Data is sourced from the [1000 Genomes Project](https://www.internationalgenome.org/data/).  \n",
        "- **Preprocessing**:  \n",
        "  - Download `.vcf` files containing genetic data.  \n",
        "  - Use tools like **bcftools** or **PLINK** to extract SNPs of interest.  \n",
        "  - Convert the processed data into `.csv` format with rows representing individuals and columns representing SNPs.  \n",
        "  - Add labels (e.g., disease presence or absence) for supervised learning.  \n",
        "\n",
        "**Example Dataset Format**:  \n",
        "| SNP1 | SNP2 | SNP3 | ... | Label |  \n",
        "|------|------|------|-----|-------|  \n",
        "| 0.1  | 0.3  | 0.2  | ... | 1     |  \n",
        "| 0.2  | 0.1  | 0.4  | ... | 0     |  "
      ],
      "metadata": {
        "id": "bhQMlSRZpHI6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CeFXItyoQ6Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('genetic_data.csv')\n",
        "X = data.drop(columns=['Label']).values\n",
        "y = data['Label'].value"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. **Data Loading and Splitting**  \n",
        "- Load the `.csv` file using **pandas**.  \n",
        "- Split the dataset into training and validation sets using **train_test_split** from Scikit-learn.  \n"
      ],
      "metadata": {
        "id": "l18Qkv_lp6Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "4qD8nwbhpa92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. **Model Architecture**  \n",
        "The system uses a feedforward neural network with the following layers:  \n",
        "- Input layer: Matches the number of SNP features.  \n",
        "- Hidden layers: Fully connected layers with ReLU activation and dropout for regularization.  \n",
        "- Output layer: A single neuron with a sigmoid activation for binary classification.  \n",
        "The model is trained using the **Adam optimizer** and **binary cross-entropy loss**"
      ],
      "metadata": {
        "id": "NHXY49iGqFCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(X_train.shape[1],)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30,\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "id": "pkWKmfi2pfCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. **Hyperparameter Tuning**  \n",
        "- The model's hyperparameters (e.g., number of neurons, dropout rate, optimizer choice) are optimized using **Keras Tuner**.  \n",
        "- A random search is conducted to find the best configuration, which is then used to retrain the model."
      ],
      "metadata": {
        "id": "m_eW6SOMqays"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
        "    model.add(layers.Dense(hp.Int('units', min_value=64, max_value=256, step=64), activation='relu'))\n",
        "    model.add(layers.Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', ['adam', 'sgd']),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    directory='tuner_results',\n",
        "    project_name='genetic_profiling'\n",
        ")\n",
        "\n",
        "tuner.search(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20)\n"
      ],
      "metadata": {
        "id": "LfPDb_YWqbTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. **Model Training**  \n",
        "- The model is trained using the training set with validation on a holdout set.  \n",
        "- Training uses a batch size of 64 and runs for 20–30 epochs, depending on early stopping criteria."
      ],
      "metadata": {
        "id": "_a0PItbRqh8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. **Model Evaluation**  \n",
        "- After training, the model is evaluated on the validation set using metrics like:  \n",
        "  - **Accuracy**  \n",
        "  - **AUC-ROC**  \n",
        "- These metrics help ensure the model generalizes well to unseen data."
      ],
      "metadata": {
        "id": "0UZxO70wqo5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Final Validation Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "ErZ_SB-sqwVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites  \n",
        "- Python 3.8+  \n",
        "- Required libraries: TensorFlow, Keras Tuner, Scikit-learn, Pandas, Numpy  \n",
        "\n",
        "### Steps  \n",
        "1. Preprocess the `.vcf` files to create a `.csv` dataset (`genetic_data.csv`).  \n",
        "2. Run the Python script to load and preprocess the data.  \n",
        "3. Train the model using the provided architecture.  \n",
        "4. Use hyperparameter tuning to optimize the model.  \n",
        "5. Save the final model and evaluate its performance."
      ],
      "metadata": {
        "id": "P-ePaJ7nq_sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results  \n",
        "The system provides probabilistic predictions for the likelihood of genetic predispositions. It can be extended for multiclass classification or integrated with external systems for broader use cases.  "
      ],
      "metadata": {
        "id": "5R7GNdpWrFMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Future Work  \n",
        "- Explore other ML algorithms like Random Forest or Gradient Boosted Trees for comparison.  \n",
        "- Extend the system for multiclass problems (e.g., multiple genetic conditions).  \n",
        "- Build a user-friendly interface for clinical use.  \n"
      ],
      "metadata": {
        "id": "_3r7_36prU3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acknowledgments  \n",
        "- **Data Source**: [1000 Genomes Project](https://www.internationalgenome.org/data/)  \n",
        "- **Tools Used**: TensorFlow, Keras Tuner, Scikit-learn, Pandas"
      ],
      "metadata": {
        "id": "KS3PNVbjrZk8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ju_R0UhJrVYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}